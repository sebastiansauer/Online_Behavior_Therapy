---
title: "BiPOCD_preparation_for_modeling"
author: "Sebastian Sauer"
date: "11 Juli 2016"
output:
  html_document:
    toc: yes
    toc_depth: 3
    number_sections: true
    code_folding: hide
---



Setup.


```{r setup, include=FALSE}

message("***starting\n***")

library(knitr)
opts_knit$set(root.dir=normalizePath('../'))

knitr::opts_chunk$set(echo = TRUE, 
                      cache = FALSE, 
                      warning = FALSE, 
                      message = FALSE)
```


Load libraries etc.
```{r libs}

library(pscl)  # pseudo R^2
library(magrittr) # piping
library(mice)  # imputation
library(readr) # csv import
library(knitr) # rmarkdown
library(tidyr) # tidying objects
library(caret) # modeling
library(ggplot2) # plotting
library(tibble) # tibble
library(dplyr) # data wrangling
library(purrr)  # functional programming



# define paths
path_data <- "~/Documents/OneDrive/Forschung/Online_Behavior_Therapy/raw_data"
path_file_data <- "~/Documents/OneDrive/Forschung/Online_Behavior_Therapy/raw_data/BiPOCD_raw_data.csv"
path_code <- "~/Documents/OneDrive/Forschung/Online_Behavior_Therapy/R_code"
path_figs <- "~/Documents/OneDrive/Forschung/Online_Behavior_Therapy/figs"
path_obj <- "~/Documents/OneDrive/Forschung/Online_Behavior_Therapy/data_objects"



# constants
red1 <- "#880011"




# overhead
write_to_file <- TRUE

```





# Variables for modeling

What variables should be included, and which not?

Include:

- sum scores
- demographics
- outcome
- CYBOCS (all)
- CGI_S_pre
- symptoms: Checking, Obsessions, contamination und symmetry
- treatment experience, including prior experience with CBT

Exclude:

- nzv variables (near zero variance)
- single items, if collapsed in sum score


(Plus ID variable for joins etc.)

```{r function_prep_data}

prep_data <- function(data_file = path_file_data, learning_type = "classification", write = FALSE) {

  require(readr)
  require(dplyr)


  # define paths
  path_data <- "~/Documents/OneDrive/Forschung/Online_Behavior_Therapy/raw_data"
  path_file_data <- "~/Documents/OneDrive/Forschung/Online_Behavior_Therapy/raw_data/BiPOCD_raw_data.csv"
  data_file <- "BiPOCD_raw_data.csv"



  # load data
  data <- read_csv(paste("raw_data/", data_file, sep = ""))

  # convert outcome to factor and relevel
  data %>%
    mutate(responder_3m_f = factor(responder_3m)) -> data

  library(testthat)
  expect_s3_class(data$responder_3m_f, "factor")

  message("dichotomy outcome variable has been converted to factor")


  data$responder_3m_f <- relevel(data$responder_3m_f, ref = "1")
  
  data$responder_3m_f <- factor(data$responder_3m_f, labels = c("negative", "positive"))


  # identify NZV variables
  data %>%
    caret::nearZeroVar(., saveMetrics = TRUE) %>%
    tibble::rownames_to_column() %>%
    filter(nzv == TRUE) -> data_nzv
  
  message("near zero variance variables have been identified")

  nzv_vars <- data_nzv$rowname

##### select variables for the analysis ######
  
  data %>%
    dplyr::select(dplyr::matches("sum|CYBOCS"),  # sumscores of scales *OR* CYBOCS
                  Depression:numberdiagnos,  # comorbidity
                  sex:OCD_treatm_exp,  # demographics
                  responder_3m_f, CYBOCS_3m,  # outcome
                  CGI_S_pre,  # clincial rating of symptoms
                  checking, obsessions, contamination, symmetry, # symptoms
                  ID,
                  CBT_OCD,  # priot experience to OCD treatment via CBT
                  -one_of(nzv_vars)) ->  # exclude nzv variables
    data_mod

  if (write == TRUE) write_csv(data_mod, path = "data_mod.csv")

  return(data_mod)

}

data_mod <- prep_data("BiPOCD_raw_data.csv")


```



# Replace/omit missing values


## Missings in the DV(s)

How many missings do we have?

```{r check_NA}
data_mod %>% select_if(function(col) sum(is.na(col)) != 0) %>% names

library(pander)
data_mod %>% 
  select_if(function(col) sum(is.na(col)) != 0) %>% 
  summarise_each(funs(sum(is.na(.)))) %>% 
  pander

# yo
```

Oh no! Some NA's in our outcome variable, that's is a sad story. That reduces the sample size (for classification). We could impute, or we could delete those cases. At least the 5 missings occur in both variables for the same cases. 


Let's quickly double check whether those cases are missing for the numeric outcome variable, too (this should be the case.)

```{r doubecheck_NA_in_DVs}

data_mod %>% 
  dplyr::select(ID, CYBOCS_3m, responder_3m_f) %>% 
  mutate(NA_flag = ((is.na(CYBOCS_3m)) | (is.na(responder_3m_f)))) %>% 
  dplyr::filter(NA_flag == TRUE) %>% 
  kable

```


Let's try to impute and see what happens.

```{r exclude_NA_cybocs_3m}
# data_mod %>% 
#  filter(!is.na(responder_3m_f), !is.na(CYBOCS_3m)) -> data_mod
```


Ok, so that makes sense. Five cases are not ours to see.



The dimension of our data set is now `r dim(data_mod)`.


## NAs in predictors

What about the rest of the variables with NAs? 

There are some variables with a lot of NA. Cure appears difficult. One way, and a sensible way, would be to exclude the culprits. Here they come:

```{r, echo = TRUE}
data_mod %>% 
  dplyr::select_if(function(col) sum(is.na(col)) >= 10) %>% names
```



```{r}
# data_mod %>% 
#  dplyr::select_if(function(col) sum(is.na(col)) < 10) -> data_mod
```

Alternatively, we could argue that better retaining a little information than none at all, so let's try to keep it.


Now the dimension of our data set is: `r dim(data_mod)`.


So how many missings do we have again?

```{r}
data_mod %>% 
  select_if(function(x) any(is.na(x))) %>% 
  summarise_each(funs(sum(is.na(.)))) %>% 
  kable
```

Let's impute them.


## Impute missing values

Imputing missing values is a science (and art) in its own right... But let's do some quick imputing.

```{r}
md.pattern(data_mod)

#data_mod2 <- data_mod

data_mod_MI <- mice(data_mod)
data_mod_imp <- mice::complete(data_mod_MI, 1)
# setwd(path_data)
if (write_to_file == TRUE) write_csv(data_mod_imp, path = "raw_data/data_mod2.csv")
# data_mod2 <- read_csv("data_mod2.csv")
data_mod2 <- data_mod_imp

```

We have taken imputed dataset #1 (out of 5, as per default) for imputation.

Now we feel so whole! :-)

Final check for missings: Here are the columns with NAs:
```{r}
data_mod2 %>% 
  select_if(function(col) any(is.na(col))) %>% names
```




## Collinearity

Let's check again for highly correlated variables. I have been informed that there might be again an issue..

```{r}

data_mod2 %>% 
  select_if(is.numeric) %>% 
  cor %>% findCorrelation(names = TRUE) -> collinear_vars

```
So this variable `r collinear_vars` is collinear to some other. Let's exclude it.

```{r}

data_mod2 %>% 
  dplyr::select(-one_of(collinear_vars)) -> data_mod2
```



# Separate train and test dataset

Let's split the data set in two parts, for training (80%) and for testing, to avoid bias from overfitting.

```{r}
set.seed(42)
trainIndex <- createDataPartition(data_mod2$responder_3m_f, p = .7,
                                  list = FALSE,
                                  times = 1)

train <- data_mod2[trainIndex, ]
test <- data_mod2[-trainIndex, ]
```



# Factor variables with sparsely populated levels -- exclude

Some variables are sparsely populated, e.g.:

```{r}
data_mod2 %>% 
  dplyr::select(medication) %>% 
  group_by(medication) %>% 
  summarise(n = n()) %>%
  kable
```

And here is the list:
```{r}
data_mod2 %>%
  select(-ID) %>%
  nearZeroVar(., saveMetrics = TRUE) %>% 
  kable

```


In order to identify sparse nominal (factor) variables, we should first dummy-code them. 

```{r exclude_sparse_variables1}

data_mod3 <- model.matrix(~ ., data = data_mod2)

data_mod3 %>% data.frame -> data_mod3

attr(data_mod3, "sparse_vars_excluded") <- FALSE
```

Now the data frame has been turned into a model.matrix (ie., all factor variables are now dummy-coded ie., binary). The number of variables (columns) is now: `r ncol(data_mod3)`. Note that the `x.intercept` variable is an artefact by the `model.matrix` function, but should be exluded nonetheless.

Let's check how many sparse variables are identified.

```{r exclude_sparse_variables2}


data_mod3 %>% 
  nearZeroVar(saveMetrics = TRUE)  %>% 
  rownames_to_column %>% 
  filter(nzv == TRUE) %>%
  dplyr::rename(predictor = rowname) -> nzv_df

nzv_df %>% 
  kable

data_mod3 %>% 
    nearZeroVar -> sparse_vars_idx

names(data_mod3)[sparse_vars_idx] -> sparse_vars


```

In sum, the number of sparse variables is `r length(sparse_vars)`.

Let's look at the distributions of the nzv variables.

```{r}
data_mod3 %>% 
  select(one_of(sparse_vars)) %>% 
  map(~table(.))
```


Is is evident that binary variables with factors where n is only 1, 2 or 3 cannot be of use. Then let's *exclude* the NZV variables.

```{r}

data_mod3 %>% 
  dplyr::select(-sparse_vars_idx) -> data_mod3

attr(data_mod3, "sparse_vars_excluded") <- TRUE

```


Maybe we better exlude the variable `ID`.

```{r}
data_mod3 %>% 
  select(-ID) -> data_mod3
```

And let's rename `responder_3m_f2` to `responder_3m_f`.

```{r}
data_mod3 %>% 
  dplyr::rename(responder_3m_f = responder_3m_f2) -> data_mod3
```



Don't forget to write resulting dataframe to disk.

```{r write_datafile_to_disk}

# setwd(path_data)
if (write_to_file == TRUE) write_csv(data_mod3, path = "raw_data/data_mod3.csv")


```

The factor variables with sparse levels (now excluded) are: 

```{r}
sparse_vars

```

The remaining number of *cols* is: `r ncol(data_mod3)`.
The remaining number of *rows* is: `r nrow(data_mod3)`.

```{r}
cat("This is the end\n")
```



