---
title: "Classical linear regression"
author: "Sebastian Sauer"
date: "`r Sys.time()`"
output: 
  html_document:
    code_folding: hide
    toc: yes
    toc_depth: 3
    number_sections: true
---


# Setup

```{r load_knitr}
library(knitr)
```


```{r knitr_opts}

opts_knit$set(root.dir=normalizePath('../'))


knitr::opts_chunk$set(echo = TRUE,
                      cache = TRUE,
                      warning = FALSE,
                      message = FALSE)
```


Load packages.


```{r libs}

source("analysis/functions/load_libs.R")
```


Define results variables.

```{r results_var}

# results/ variables
mod_results_regression <- list()
regr_varimp <- list()  # var.imp only
```



Prepare overhead.

```{r overhead}
registerDoMC(cores = 4)
```




Play or work (test it and recompute vs. rely on cached data)

```{r play_or_work, echo = TRUE}
recompute <- TRUE
test_it <- TRUE

write_to_file <- FALSE

```



Define paths.

```{r paths}
source("analysis/functions/paths.R")
```

Load data and data-objects.


```{r read_data}
data <- read_csv("raw_data/data_mod3.csv")  

load(file = "data_objects/mod_results.Rda")
load("data_objects/important_predictors.Rda")
load("data_objects/important_predictors_overview.Rda")

```


Dimension of data:

Rows: `r dim(data)[1]`.
Cols: `r dim(data)[2]`.



Check if *numeric* outcome variables is present in data frame. 
Check if *binary* outcome variable is present in data frame.

```{r detect_outcome_vars}
str_detect(names(data), "CYBOCS") %>% any %>% expect_true

str_detect(names(data), "responder_3m") %>% any %>% expect_true

```


# Simple non-sense regression models

If the number of predictors (p) equals the number of cases (n), then $R^2$ will approach 1. Hence, model fit *per se* is of limited or no value for deciding on the vlaue of a model.





## Numeric outcome

Outcome: `CYBOCS_3m`.

```{r nonsense_lm1}
data %>% 
 sample_n(45, replace = FALSE) %>% 
  na.omit -> data2



if ("responder_3m_f" %in% names(data)) {
  dplyr::select(data2, -responder_3m_f) -> data2}
  

lm(CYBOCS_3m ~ ., data = data2) %>% summary %>% tidy %>% kable(digits = 3)
```

$R^2$ of this model is: `r summary(lm(CYBOCS_3m ~ ., data = data2))$r.squared`.

## Binary regression models
Outcome: `responder_3m_f`.

```{r nonsense_lm2}
data %>% 
 dplyr::sample_n(45, replace = FALSE) %>% 
  na.omit -> data2


if ("CYBOCS_3m" %in% names(data)) {
  dplyr::select(data2, -CYBOCS_3m) -> data2}
  

glm(responder_3m_f ~ ., data = data2, family = "binomial") %>% summary
```


$R^2$ of this model is: 

```{r rsquared__nonsense_model}
glm(data2$responder_3m_f ~ .,
               data = data2,
               family = "binomial",
               control = list(maxit = 50)) %>% 
  pR2(.) %>% 
  print

```



# Bivariate variable selection models (regression/ numeric outcome)

Now, let's take the *full* sample, and check whether/how strong each predictor is correlated with the (metric) outcome. Predictors which are correlated (p<.05) with the outcome will be used for the predicting the outcome in the next step.

As the sample size is low, it can be argued that it is better not to split up the sample, but to use some overfitting-aware measure on the performance of the whole sample. Adjusted $R^2$ would be some sensible measure.


## Predictor selection

We compute a regression with *one* predictor, and repeat that for each predictor. The p-value is taken as criterion of "relevant" predictor. This choise is debatable, but let's leave that for now.

```{r univariate_feature_selection_classical_lm1}

data %>% 
  dplyr::select(-c(responder_3m_f, CYBOCS_3m)) %>% 
  map(~lm(data$CYBOCS_3m ~ .x, data = data)) %>%
  map(tidy, conf.int = TRUE) %>% 
  # map(summary) %>% 
  # map("coefficients") %>% 
  do.call(rbind.data.frame, .) %>% 
  rownames_to_column %>% 
  as_tibble %>% 
  dplyr::rename(predictor = rowname, p = p.value, b = estimate, SE = std.error, t = statistic) %>% 
  # setNames(c("predictor", "b", "SE", "t", "p", "conf.low", "conf.hi")) %>% 
  dplyr::arrange(p) %>% 
  filter(!str_detect(term, "(Intercept)")) %>% 
  dplyr::select(-term) %>% 
  mutate(predictor = str_sub(predictor, start = 1, end = str_length(predictor)-2))  -> mod_results$classical_01$univariate_lm_selection



mod_results$classical_01$univariate_lm_selection %>% 
  mutate_at(vars(b, SE, t, conf.low, conf.high), funs(round(., 2))) %>% 
  mutate(p = round(p, 3)) %>% 
  mutate(p = ifelse(p == 0, 0.001, p)) %>% 
  kable
```

According to this reasoning, we should retain the following variables (p < .05):


```{r lm1_signif_predictors}

mod_results$classical_01$univariate_lm_selection %>% 
  filter(p < .05) %>% 
  filter(!str_detect(predictor, "(Intercept)")) -> mod_results$classical_01$univariate_lm_selection_signif
  
mod_results$classical_01$univariate_lm_selection_signif %>% 
  mutate_at(vars(b, SE, t), funs(round(., 2))) %>% 
  mutate(p = ifelse(p < 0.01, 0.001, round(p, 3))) %>% 
  kable
```

In sum, `r nrow(mod_results$classical_01$univariate_lm_selection_signif)` variables were chosen. 


Let's also have a look at the (adj.) R squared of each model




```{r classical_lm1_r2_preds}
  
data %>% 
  dplyr::select(-c(responder_3m_f, CYBOCS_3m)) %>% 
  map(~lm(data$CYBOCS_3m ~ .x, data = data)) %>% 
  map(glance) %>% 
  do.call(rbind.data.frame, .) %>% 
  rownames_to_column %>% 
  as_tibble %>% 
  arrange(-r.squared) %>% 
  kable(digits = 3)


data %>% 
  dplyr::select(-c(responder_3m_f, CYBOCS_3m)) %>% 
  map(~lm(data$CYBOCS_3m ~ .x, data = data)) %>% 
  map(glance) %>% 
  do.call(rbind.data.frame, .) %>% 
  rownames_to_column %>% 
  as_tibble %>% 
  ggplot(aes(x = reorder(rowname, adj.r.squared), y = adj.r.squared)) +
  geom_point() +
  coord_flip() + 
  scale_y_continuous(labels = scales::percent) +
  xlab("predictors") +
  ylab(expression(R^{2}))
  
```

And now the $R^2$ for the significant predictors only:


```{r classical_lm1_r2_signif_preds}


data %>% 
  dplyr::select(one_of(mod_results$classical_01$univariate_lm_selection_signif$predictor)) -> mod_results$classical_01$univariate_signif_preds_df

mod_results$classical_01$univariate_signif_preds_df %>%   
  map(~lm(data$CYBOCS_3m ~ .x, data = mod_results$classical_01$univariate_signif_preds_df)) %>%   map(glance) %>% 
  do.call(rbind.data.frame, .) %>% 
  rownames_to_column %>% 
  as_tibble %>% 
  arrange(-r.squared) %>% 
  kable(digits = 3)


mod_results$classical_01$univariate_signif_preds_df %>%   
  map(~lm(data$CYBOCS_3m ~ .x, data = mod_results$classical_01$univariate_signif_preds_df)) %>%   map(glance) %>% 
  do.call(rbind.data.frame, .) %>% 
  rownames_to_column %>% 
  as_tibble %>% 
  arrange(-r.squared) %>% 
  ggplot(aes(x = reorder(rowname, adj.r.squared), y = adj.r.squared)) +
  geom_point() +
  coord_flip() + 
  scale_y_continuous(labels = scales::percent) +
  xlab("significant predictors") +
  ylab(expression(R^{2}))
```



## Regression with univariate predictor selection (numeric outcome)

We take these predictors (which showed a statistical significant assocation with the outcome in bivariate regressions), and submit them to a multivariate regression.

```{r classical_lm1_results}

data %>% 
  dplyr::select(one_of(mod_results$classical_01$univariate_lm_selection_signif$predictor))  -> data_regr_univar_signif

lm(data$CYBOCS_3m ~ . , data = data_regr_univar_signif) %>% 
  tidy(conf.int = TRUE) %>% 
  arrange(p.value) ->  mod_results$classical_01$lm1_tidy



mod_results$classical_01$lm1_tidy %>% 
  kable(digits = 3)



```

## Number of significant predictors

How many predictors reach statistical significance?

```{r lm1_nr_signif_preds}
mod_results$classical_01$lm1_tidy %>% 
  filter(p.value < .05) %>% 
  nrow
```



The same table as above, somewhat more beautiful:

```{r lm1_stargazer, results = "asis"}
stargazer(mod_results$classical_01$lm1_tidy, type = "html")

```


Let's have a look at the predictors which reached statistical significance:

```{r lm1_results_signif_only}
mod_results$classical_01$lm1_tidy %>% 
  filter(p.value < .05) %>% 
  mutate_if(is.numeric, round, digits = 2) -> mod_results$classical_01$signif_preds

mod_results$classical_01$signif_preds %>% 
  kable(digits = 3)

```

## Adj. R squared

*Adjusted* $R^2$ of the *whole* dataset is:

```{r lm1_adj_rsquared}
lm(data$CYBOCS_3m ~ . , data = data_regr_univar_signif) %>% 
  glance %>% 
  arrange(-r.squared) %>% 
  kable
```

## Regression diagnistics

```{r lm1_regr_diagnostics_augment}
lm(data$CYBOCS_3m ~ . , data = data_regr_univar_signif) %>% 
  augment %>% 
  kable(digits = 3)
```


## Variable importance

Let's take the p-value of the univariate regression (ie., with one predictor) as the variable importance of that predictor.

```{r lm1_varimp}

if (nrow(mod_results$classical_01$signif_preds) > 0 ){
  mod_results$classical_01$signif_preds$rank <-   min_rank(mod_results$classical_01$signif_preds$p)
  
  if (test_it) message("if_clause is entered")
  
  tibble(
    name =  mod_results$classical_01$signif_preds$predictor,
    value = mod_results$classical_01$signif_preds$b,
    rank = min_rank(mod_results$classical_01$signif_preds$p)
  ) -> regr_varimp$classical_lm1
} else {
  regr_varimp$classical_lm1 <- NA
  if (test_it) message("if_clause is NOT entered")
}

```




# Bivariate variable selection models (classification/ binary outcome)

Now, let's take the *full* sample, and check whether/how strong each predictor is associated with the (*binary*) outcome. Those predictors will be used for the predicting the outcome in the next step.

As the sample size is low, it can be argued that it is better not to split up the sample, but to use some overfitting-aware measure on the performance of the whole sample. Adjusted $R^2$ would be some sensible measure.

## Predictor selection

### Univariate (one predictor) logistic regression models
Now, let's run a logistic regression for each predictor (with `responder_3m_f` as outcome), and check the results.

Here are the p-values for each predictor (ie., one model for each predictor)
```{r univariate_feature_selection_glm2}
data %>% 
  dplyr::select(-c(responder_3m_f, CYBOCS_3m)) %>% 
  map(~glm(data$responder_3m_f ~ .x, data = data, family = "binomial")) %>% 
  map(summary) %>% 
  map("coefficients") %>% 
  map_dbl(8) %>%  # that's the p-value
  tidy %>% 
  dplyr::rename(pvalue = x) %>% 
  dplyr::arrange(pvalue)  -> mod_results$classical_02$univariate_lm_selection



kable(mod_results$classical_02$univariate_lm_selection, digits = 3)
```

With some more details:

```{r univariate_feature_selection_glm2_details}
data %>% 
  dplyr::select(-c(responder_3m_f, CYBOCS_3m)) %>% 
  map(~glm(data$responder_3m_f ~ .x, data = data, family = "binomial")) %>% 
  map(tidy, conf.int = TRUE) %>% 
  do.call(rbind.data.frame, .) %>% 
  rownames_to_column %>% 
  dplyr::arrange(p.value)  -> mod_results$classical_02$univariate_lm_selection_details



kable(mod_results$classical_02$univariate_lm_selection_details, digits = 3)
```


### $R^2$ of the simple regression models

Here is the model performance.

```{r univariate_feature_selection_glm2_glance}
data %>% 
  dplyr::select(-c(responder_3m_f, CYBOCS_3m)) %>% 
  map(~glm(data$responder_3m_f ~ .x, data = data, family = "binomial")) %>% 
  map(glance) %>% 
  do.call(rbind.data.frame, .) %>% 
  rownames_to_column %>% 
  as_tibble %>% 
  dplyr::rename(predictor = rowname)  -> mod_results$classical_02$univariate_lm_selection_glance



kable(mod_results$classical_02$univariate_lm_selection_glance, digits = 3)
```


Pseudo $R^2$

```{r univariate_feature_selection_glm2_pR2}
data %>% 
  dplyr::select(-c(responder_3m_f, CYBOCS_3m)) %>% 
  map(~glm(data$responder_3m_f ~ .x, 
           data = data, 
           family = "binomial")) %>% 
  map(pR2) %>% 
  do.call("rbind.data.frame", .) %>% 
  rownames_to_column %>% 
  as_tibble %>% 
  setNames(c("predictor", "llh", "llhNull", "G2", "McFadden", "r2ML", "r2CU")) %>% 
  arrange(-McFadden) -> mod_results$classical_02$univariate_lm_selection_pR2



kable(mod_results$classical_02$univariate_lm_selection_pR2, digits = 3)
```



### Regression diagnostics
And here are the regression diagnostics:


```{r univariate_feature_selection_glm2_augment, include = FALSE}
data %>% 
  dplyr::select(-c(responder_3m_f, CYBOCS_3m)) %>% 
  map(~glm(data$responder_3m_f ~ .x, data = data, family = "binomial")) %>% 
  map(augment) %>% 
  do.call(rbind.data.frame, .) %>% 
  rownames_to_column %>% 
  as_tibble %>% 
  dplyr::rename(predictor = rowname)  -> mod_results$classical_02$univariate_lm_selection_glance



kable(mod_results$classical_02$univariate_lm_selection_glance, digits = 3)
```


According to this reasoning, we should retain the following variables (p < .05):


```{r classical_glm_02_signif_predictors}
mod_results$classical_02$univariate_lm_selection %>% 
  filter(pvalue < .05) -> mod_results$classical_02$univariate_lm_selection_signif
  
kable(mod_results$classical_02$univariate_lm_selection_signif, digits = 3)
```

In sum, `r nrow(mod_results$classical_02$univariate_lm_selection_signif)` variables were chosen. 



## Classification with univariate predictor selection

We take these predictors (which showed a statistical significant assocation with the outcome in bivariate regressions), and submit them to a multivariate regression.

```{r classical_glm2_results}

data %>% 
  dplyr::select(one_of(mod_results$classical_02$univariate_lm_selection_signif$names)) %>% 
  do(tidy(glm(data$responder_3m_f ~ . , 
              data = ., 
              family = "binomial",
              control = list(maxit = 50)))) %>% 
  dplyr::rename(predictor = term, logodds_b = estimate, SE = std.error, T = statistic, p = p.value) %>%   
  arrange(p) ->  mod_results$classical_02$lm2_tidy


mod_results$classical_02$lm2_tidy %>% 
  kable(digits = 3)


```




## Number of significant predictors

How many predictors reach statistical significance?

```{r glm2_nr_signif_preds}
mod_results$classical_02$lm2_tidy %>% 
  filter(p < .05) %>% 
  nrow
```



The same table as above, somewhat more beautiful:

```{r glm2_stargazer, results = "asis"}
stargazer(mod_results$classical_02$lm2_tidy, type = "html")

```


Let's have a look at the predictors which reached statistical significance:

```{r glm2_results_signif_only}
mod_results$classical_02$lm2_tidy %>% 
  filter(p < .05)  -> mod_results$classical_02$signif_preds

mod_results$classical_02$signif_preds %>% 
  kable(digits = 3)

```

Let's convert their log odds to odds:

```{r glm2_results_logodds_to_odds}

data %>% 
  dplyr::select(one_of(mod_results$classical_02$univariate_lm_selection_signif$names)) -> mod_results$classical_02$univariate_lm_selection_df 


  glm(data$responder_3m_f ~ . , 
      data = mod_results$classical_02$univariate_lm_selection_df, 
      family = "binomial", 
      control = list(maxit = 50)) -> mod_results$classical_02$fit
  
exp(coef(mod_results$classical_02$fit)) %>% tidy %>% setNames(c("predictor", "OR"))

```

Note that the levels of the outcome variable are:
```{r levels_outcoem}
str(data$responder_3m_f)
unique(data$responder_3m_f)
```

where $0$ stands for "no", and $1$ for "yes".


```{r check_n}
expect_equal(nrow(mod_results$classical_02$fi$data), 61)
```


## Adj. R squared

*Adjusted* $R^2$ of the *whole* dataset is:

```{r adj_rsquared_glm2}

mod_results$classical_02$fit %>% 
  pscl::pR2(mod_results$classical_02$fit) %>% 
  print
  

```

## Variable importance

Let's take the p-value of the univariate regression (ie., with one predictor) as the variable importance of that predictor.

```{r glm2_varimp}

if (nrow(mod_results$classical_02$signif_preds) > 0 ){
  mod_results$classical_02$signif_preds$rank <-   min_rank(mod_results$classical_02$signif_preds$p)
  
  if (test_it) message("if_clause is entered")
  
  tibble(
    name =  mod_results$classical_02$signif_preds$predictor,
    value = mod_results$classical_02$signif_preds$b,
    rank = min_rank(mod_results$classical_02$signif_preds$p)
  ) -> regr_varimp$classical_glm2
} else {
  regr_varimp$classical_glm2 <- NA
  if (test_it) message("if_clause is NOT entered")
}

```


# Clean-up

Save results

```{r save_results}
save(mod_results, file = "data_objects/mod_results.Rda")
save(regr_varimp, file = "data_objects/regr_varimp.Rda")

```






